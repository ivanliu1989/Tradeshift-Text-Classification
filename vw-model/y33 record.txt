vw -d train_y33.vw --loss_function logistic -b 28 -l 0.6 -q :: -c -k --passes 3 -f model_y33_improved.vw --holdout_period 50 --decay_learning_rate 0.9 
### 0.055897 (y33) ###

======================================================================================================================================================
-l 0.4/0.3
### 0.055384/0.0714611 ###

======================================================================================================================================================
--passes 10
### 0.536421  ###

======================================================================================================================================================
--stage_poly --batch_sz 800000 --batch_sz_no_doubling --sched_exponent 1.96 --save_resume --l2 6e-8 --l1 1.2e-8 --compressed
###  ###

======================================================================================================================================================
--feature_mask model_y33_improved.vw
###  ###

======================================================================================================================================================
--adaptive --invariant --power_t 0.5 -l 0.1
### 0.0648381 ###


--adaptive 50
--invariant 2.7
none 2.5

--exact_adaptive_norm and --adaptive turns on an individual learning rate for each feature. These learning rates are adjusted automatically according to a data-dependent schedule. These learning rates give an improvement when the data have many features, but they can be slightly slower especially when used in conjunction with options that cause examples to have many non-zero features such as -q and --ngram. Of the two --exact_adaptive_norm used to be recommended in the past, it is now the default so there's no need to specify it.

--invariant                      use safe/importance aware updates
                                 (on by default)
